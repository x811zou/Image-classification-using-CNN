{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nets import inception_utils, inception_v3\n",
    "from glob import glob\n",
    "import imageio\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_init_fn():\n",
    "    # Load from .ckpt file\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=[\"InceptionV3/Logits/Conv2d_1c_1x1/weights:0\", \"InceptionV3/Logits/Conv2d_1c_1x1/biases:0\"])\n",
    "    global_step_reset = tf.assign(tf.train.get_or_create_global_step(), 0)\n",
    "    slim_init_fn = slim.assign_from_checkpoint_fn(\"./inception_v3.ckpt\",variables_to_restore,ignore_missing_vars=True)\n",
    "    return slim_init_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_train = df[df[\"label\"]==0].iloc[:40000]\n",
    "df_one_train = df[df[\"label\"]==1].iloc[:40000]\n",
    "\n",
    "df_zero_val = df[df[\"label\"]==0].iloc[40000:44000]\n",
    "df_one_val = df[df[\"label\"]==1].iloc[40000:44000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "arg_scope = tf.contrib.framework.arg_scope\n",
    "\n",
    "# Set Params\n",
    "MAX_EPOCH = 150000\n",
    "NUM_CLASSES = 2\n",
    "NUM_IMG_FROM_EACH_CLASS = 50\n",
    "input_size = NUM_IMG_FROM_EACH_CLASS * NUM_CLASSES\n",
    "VALIDATION_INTERVAL = 500\n",
    "START_LR = 1e-04\n",
    "DECAY_STEP = 10000 / 63 * 10\n",
    "DECAY_RATE = 0.98\n",
    "RETRAIN_NAMES = [\"Logits\", \"Mixed_7\"]\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    LOG_DIR = \"./saved_model/Inception_\" + str(START_LR) + \"_\" + str(DECAY_STEP) + \"_\" + str(DECAY_RATE) + \"_\" + RETRAIN_NAMES[-1]\n",
    "else:\n",
    "    LOG_DIR = \"/work/<netid>/saved_model/Inception_\" + str(START_LR) + \"_\" + str(DECAY_STEP) + \"_\" + str(DECAY_RATE) + \"_\" + RETRAIN_NAMES[-1]\n",
    "\n",
    "\n",
    "session_config = tf.ConfigProto(log_device_placement=False)\n",
    "session_config.gpu_options.allow_growth = True\n",
    "\n",
    "# Define Graph\n",
    "one_hot_encoder = OneHotEncoder(2)\n",
    "one_hot_encoder.fit(np.arange(2).reshape(-1,1))\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    img_holder = tf.placeholder(shape=[input_size,96,96,3], dtype=tf.float32, name=\"Img_Holder\")\n",
    "    label_holder = tf.placeholder(shape=[input_size,2], dtype=tf.float32, name=\"Label_Holder\")\n",
    "    img = tf.Variable(img_holder, name=\"Img_Var\", trainable=False)\n",
    "    label = tf.Variable(label_holder, name=\"Label_Var\", trainable=False)\n",
    "    img_assign = img.assign(img_holder, name=\"Img_Assign\")\n",
    "    label_assign = label.assign(label_holder, name=\"Label_Assign\")\n",
    "    \n",
    "    img_holder_val = tf.placeholder(shape=[input_size,96,96,3], dtype=tf.float32, name=\"Img_Holder_val\")\n",
    "    label_holder_val = tf.placeholder(shape=[input_size,2], dtype=tf.float32, name=\"Label_Holder_val\")\n",
    "    img_val = tf.Variable(img_holder_val, name=\"Img_Var_val\", trainable=False)\n",
    "    label_val = tf.Variable(label_holder_val, name=\"Label_Var_val\", trainable=False)\n",
    "    img_assign_val = img_val.assign(img_holder_val, name=\"Img_Assign_val\")\n",
    "    label_assign_val = label_val.assign(label_holder_val, name=\"Label_Assign_val\")\n",
    "\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        logits, end_points = inception_v3.inception_v3(img, num_classes=2, create_aux_logits=False, is_training=True)\n",
    "        pred = slim.softmax(logits, scope=\"Prediction\")\n",
    "        logits_val, _ = inception_v3.inception_v3(img_val, num_classes=2, create_aux_logits=False, is_training=False, reuse=tf.AUTO_REUSE)\n",
    "        pred_val = slim.softmax(logits_val, scope=\"Prediction_Val\")\n",
    "    _, accuracy_val = tf.metrics.accuracy(tf.math.argmax(pred_val, axis=1), tf.math.argmax(label_val, axis=1))\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(label, logits)\n",
    "    total_loss = tf.losses.get_total_loss()\n",
    "    loss_val = tf.losses.softmax_cross_entropy(label_val, logits_val, loss_collection=\"validation\")\n",
    "    \n",
    "    retrain_list = []\n",
    "    for v in tf.trainable_variables():\n",
    "        for n in RETRAIN_NAMES:\n",
    "            if n in v.name:\n",
    "                retrain_list += [v]\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(START_LR, tf.train.get_or_create_global_step(), DECAY_STEP, DECAY_RATE)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_tensor = slim.learning.create_train_op(total_loss, optimizer=opt, variables_to_train=retrain_list)\n",
    "    # Creat Summary\n",
    "    slim.summaries.add_scalar_summary(total_loss, 'cross_entropy_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(learning_rate, 'learning_rate', 'training')\n",
    "    slim.summaries.add_scalar_summary(loss_val, 'validation_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(loss_val-total_loss, 'validation_delta', 'losses')\n",
    "    slim.summaries.add_scalar_summary(accuracy_val, 'validation_accuracy', 'accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step_fn(sess, train_op, global_step, train_step_kwargs):\n",
    "    \"\"\"\n",
    "    slim.learning.train_step():\n",
    "    train_step_kwargs = {summary_writer:, should_log:, should_stop:}\n",
    "    \"\"\"\n",
    "#     train_step_fn.step += 1  # or use global_step.eval(session=sess)\n",
    "    input_df = [df_zero_train.sample(NUM_IMG_FROM_EACH_CLASS), df_one_train.sample(NUM_IMG_FROM_EACH_CLASS)]\n",
    "    input_path = np.array([input_df[i][\"id\"] for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(\"./train/\"+i+\".tif\") for i in input_path]).astype(np.float32)\n",
    "\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    sess.run([img_assign,label_assign], feed_dict={img_holder:input_images, label_holder:labels})\n",
    "#     print sess.run([img,label])\n",
    "\n",
    "    # calc training losses\n",
    "    total_loss, should_stop = slim.learning.train_step(sess, train_op, global_step, train_step_kwargs)\n",
    "\n",
    "\n",
    "    # validate on interval\n",
    "    if global_step.eval(session=sess) % VALIDATION_INTERVAL == 0:\n",
    "        input_df_val = [df_zero_val.sample(NUM_IMG_FROM_EACH_CLASS), df_one_val.sample(NUM_IMG_FROM_EACH_CLASS)]\n",
    "        input_path_val = np.array([input_df_val[i][\"id\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "        input_images_val = np.array([imageio.imread(\"./train/\"+i+\".tif\") for i in input_path_val]).astype(np.float32)\n",
    "\n",
    "        labels_val = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "        input_images_val, labels_val = shuffle(input_images_val, labels_val)\n",
    "        labels_val = one_hot_encoder.transform(labels_val).toarray()\n",
    "        \n",
    "        sess.run([img_assign_val,label_assign_val,logits_val,accuracy_val], \n",
    "                 feed_dict={img_holder_val:input_images_val, label_holder_val:labels_val})\n",
    "        validiate_loss = sess.run(loss_val)\n",
    "    \n",
    "        \n",
    "#    print(\">> global step {}:    train={}   validation={}  delta={}\".format(global_step.eval(session=sess), \n",
    "#                        total_loss, loss_val, loss_val-total_loss))\n",
    "\n",
    "\n",
    "    return [total_loss, should_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    \n",
    "    # Train Set    \n",
    "    input_df = [df_zero_train.sample(NUM_IMG_FROM_EACH_CLASS), df_one_train.sample(NUM_IMG_FROM_EACH_CLASS)]\n",
    "    input_path = np.array([input_df[i][\"id\"] for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(\"./train/\"+i+\".tif\") for i in input_path]).astype(np.float32)\n",
    "\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    # Val Set\n",
    "    input_df_val = [df_zero_val.sample(NUM_IMG_FROM_EACH_CLASS), df_one_val.sample(NUM_IMG_FROM_EACH_CLASS)]\n",
    "    input_path_val = np.array([input_df_val[i][\"id\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images_val = np.array([imageio.imread(\"./train/\"+i+\".tif\") for i in input_path_val]).astype(np.float32)\n",
    "\n",
    "    labels_val = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "    input_images_val, labels_val = shuffle(input_images_val, labels_val)\n",
    "    labels_val = one_hot_encoder.transform(labels_val).toarray()\n",
    "\n",
    "    slim.learning.train(\n",
    "        train_tensor,\n",
    "        LOG_DIR,\n",
    "        log_every_n_steps=1,\n",
    "        number_of_steps=MAX_EPOCH,\n",
    "        graph=g,\n",
    "        save_summaries_secs=60,\n",
    "        save_interval_secs=300,\n",
    "        init_fn=get_checkpoint_init_fn(),\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        train_step_fn = train_step_fn,\n",
    "        session_config=session_config,\n",
    "        init_feed_dict = {img_holder:input_images, label_holder:labels, img_holder_val: input_images_val, label_holder_val: labels_val})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
